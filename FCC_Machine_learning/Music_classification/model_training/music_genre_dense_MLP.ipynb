{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy.ndimage.measurements import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa, librosa.display\n",
    "import math\n",
    "import operator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"../music_data/data.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(DATASET_PATH, \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "    # convert lists to numpy arrays\n",
    "    inputs = np.array(data[\"mfcc\"])\n",
    "    labels = np.array(data[\"labels\"])\n",
    "    genres = data[\"mapping\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and test sets\n",
    "inputs_train, inputs_test, labels_train, labels_test = train_test_split(inputs, labels, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network architecture\n",
    "model = keras.Sequential([\n",
    "    # input layer\n",
    "    keras.layers.Flatten(input_shape=(inputs.shape[1], inputs.shape[2])),\n",
    "\n",
    "    # 1st hidden layer\n",
    "    keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    # 2nd hidden layer\n",
    "    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    # 3rd hidden layer\n",
    "    keras.layers.Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "\n",
    "    # output layer\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1690)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               865792    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 1,014,218\n",
      "Trainable params: 1,014,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile network\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "checkpoint_path = \"../extra_training/dense_genres.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.4034 - accuracy: 0.3911 - val_loss: 2.3690 - val_accuracy: 0.4357\n",
      "\n",
      "Epoch 00001: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.3527 - accuracy: 0.4024 - val_loss: 2.3517 - val_accuracy: 0.4393\n",
      "\n",
      "Epoch 00002: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.3475 - accuracy: 0.4025 - val_loss: 2.3550 - val_accuracy: 0.4307\n",
      "\n",
      "Epoch 00003: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 2.3053 - accuracy: 0.4124 - val_loss: 2.3546 - val_accuracy: 0.4571\n",
      "\n",
      "Epoch 00004: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2560 - accuracy: 0.4331 - val_loss: 2.2729 - val_accuracy: 0.4436\n",
      "\n",
      "Epoch 00005: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2394 - accuracy: 0.4338 - val_loss: 2.2600 - val_accuracy: 0.4557\n",
      "\n",
      "Epoch 00006: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.2070 - accuracy: 0.4372 - val_loss: 2.2378 - val_accuracy: 0.5057\n",
      "\n",
      "Epoch 00007: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1680 - accuracy: 0.4518 - val_loss: 2.1965 - val_accuracy: 0.4557\n",
      "\n",
      "Epoch 00008: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1698 - accuracy: 0.4472 - val_loss: 2.2385 - val_accuracy: 0.4800\n",
      "\n",
      "Epoch 00009: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.1217 - accuracy: 0.4611 - val_loss: 2.1897 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00010: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0792 - accuracy: 0.4635 - val_loss: 2.1935 - val_accuracy: 0.4843\n",
      "\n",
      "Epoch 00011: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0821 - accuracy: 0.4644 - val_loss: 2.1343 - val_accuracy: 0.4836\n",
      "\n",
      "Epoch 00012: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 2.0383 - accuracy: 0.4676 - val_loss: 2.1290 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00013: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9973 - accuracy: 0.4763 - val_loss: 2.1427 - val_accuracy: 0.5043\n",
      "\n",
      "Epoch 00014: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9854 - accuracy: 0.4853 - val_loss: 2.1355 - val_accuracy: 0.5029\n",
      "\n",
      "Epoch 00015: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9625 - accuracy: 0.4881 - val_loss: 2.0848 - val_accuracy: 0.4850\n",
      "\n",
      "Epoch 00016: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.9458 - accuracy: 0.4924 - val_loss: 2.0836 - val_accuracy: 0.4886\n",
      "\n",
      "Epoch 00017: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 1s 5ms/step - loss: 1.9061 - accuracy: 0.4915 - val_loss: 2.1218 - val_accuracy: 0.4857\n",
      "\n",
      "Epoch 00018: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8695 - accuracy: 0.5174 - val_loss: 2.0623 - val_accuracy: 0.5014\n",
      "\n",
      "Epoch 00019: saving model to trained_dense_model\\dense_genres.ckpt\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 1s 6ms/step - loss: 1.8497 - accuracy: 0.5256 - val_loss: 2.0374 - val_accuracy: 0.5057\n",
      "\n",
      "Epoch 00020: saving model to trained_dense_model\\dense_genres.ckpt\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "history = model.fit(inputs_train, labels_train, \n",
    "            validation_split=0.2,\n",
    "            epochs=20,\n",
    "            batch_size=32,\n",
    "            callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step - loss: 2.0620 - accuracy: 0.5128\n",
      "Accuracy on test set is 0.5128375887870789\n"
     ]
    }
   ],
   "source": [
    "# evaluate on the test set\n",
    "test_loss, test_accuracy = model.evaluate(inputs_test, labels_test, verbose=1)\n",
    "print(\"Accuracy on test set is\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a633f84fa724>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot accuracy and error over the epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# create the accuracy subplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# plot accuracy and error over the epochs\n",
    "_, axs = plt.subplots(2, figsize=(12, 5))\n",
    "\n",
    "# create the accuracy subplot\n",
    "axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].legend(loc=\"lower right\")\n",
    "axs[0].set_title(\"Accuracy eval\")\n",
    "\n",
    "# create the error subplot\n",
    "axs[1].plot(history.history[\"loss\"], label=\"train loss\")\n",
    "axs[1].plot(history.history[\"val_loss\"], label=\"test loss\")\n",
    "axs[1].set_ylabel(\"Loss\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend(loc=\"upper right\")\n",
    "axs[1].set_title(\"Loss eval\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected index: 6, Predicted index: 6\n",
      "Predicted genre of the audio file is: metal\n"
     ]
    }
   ],
   "source": [
    "# test prediction\n",
    "SONG_NO = 102\n",
    "inputs_test[SONG_NO].shape\n",
    "reshaped = inputs_test[SONG_NO][np.newaxis, ...]\n",
    "\n",
    "prediction = model.predict(reshaped)\n",
    "predicted_index = np.argmax(prediction)\n",
    "print(\"Expected index: {}, Predicted index: {}\".format(labels_test[SONG_NO], predicted_index))\n",
    "print(\"Predicted genre of the audio file is:\", genres[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a custom song\n",
    "file = \"../music_files/matt.wav\"\n",
    "data, sr = librosa.load(file) # data = sr * time (ex. 22050 * 30sec of data in data array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694 seconds\n"
     ]
    }
   ],
   "source": [
    "# calculate the track duration in sec\n",
    "track_duration = math.floor(data.shape[0]/sr)\n",
    "print(track_duration, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for preprocessing the file (must be same as the trained files)\n",
    "NUM_SEGMENT = track_duration//3     # cuts the track to segments\n",
    "N_MFCC=13\n",
    "N_FFT=2048                          # no. of samples per STFT window (length of the windowed signal)\n",
    "HOP_LENGTH=512                      # number of audio samples between adjancent STFT columns\n",
    "NUM_SAMPLES_PER_SEGMENT = 66150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing file for prediction\n",
    "prediction_mfcc = []\n",
    "for s in range(NUM_SEGMENT):\n",
    "    start_sample = NUM_SAMPLES_PER_SEGMENT * s\n",
    "    end_sample = start_sample + NUM_SAMPLES_PER_SEGMENT\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(data[start_sample:end_sample], sr=sr, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "    mfcc = mfcc.T\n",
    "\n",
    "    # store MFCC for segment\n",
    "    prediction_mfcc.append(mfcc.tolist())\n",
    "prediction_mfcc = np.array(prediction_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction_mfcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0500a3c56f4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction_mfcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction_mfcc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_mfcc' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_mfcc[4].shape\n",
    "plt.plot(prediction_mfcc[4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict for storing multiple genre values with count\n",
    "predicted_values = {}\n",
    "for i in range(prediction_mfcc.shape[0]):\n",
    "    prediction = model.predict(prediction_mfcc[i][np.newaxis, ..., np.newaxis])\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_values[genres[predicted_index]] = predicted_values.get(genres[predicted_index], 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your song is predicted to be of a country genre.\n"
     ]
    }
   ],
   "source": [
    "# pulling the genre with max occurences in dict and printing the predicted value\n",
    "predicted_genre = max(predicted_values.items(), key=operator.itemgetter(1))[0]\n",
    "print(f\"Your song is predicted to be of a {predicted_genre} genre.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genre percentages:\n",
      "\treggae: 5.19%\n",
      "\tjazz: 19.91%\n",
      "\tclassical: 9.96%\n",
      "\tblues: 16.45%\n",
      "\tcountry: 24.24%\n",
      "\tdisco: 3.03%\n",
      "\trock: 2.16%\n",
      "\tpop: 19.05%\n"
     ]
    }
   ],
   "source": [
    "# give % of all genres the song is predicted to be\n",
    "sum_all_values = sum(predicted_values.values())\n",
    "print(\"Predicted genre percentages:\")\n",
    "for k, v in predicted_values.items():\n",
    "    print(f\"\\t{k}: {round(v/sum_all_values*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# librosa.display.waveplot(data, sr=sr)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Amplitude\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft -> spectrum\n",
    "# fft = np.fft.fft(data)\n",
    "# magnitude = np.abs(fft)\n",
    "# frequency = np.linspace(0 , sr, len(magnitude))\n",
    "\n",
    "# left_frequency = frequency[:int(len(frequency)/2)]\n",
    "# left_magnitude = magnitude[:int(len(frequency)/2)]\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.plot(left_frequency, left_magnitude)\n",
    "# plt.xlabel(\"Frequency\")\n",
    "# plt.ylabel(\"Magnitude\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stft -> spectogram          \n",
    "# stft = librosa.core.stft(data, hop_length=HOP_LENGTH, n_fft=N_FFT)\n",
    "# spectogram = np.abs(stft)\n",
    "\n",
    "# log_spectogram = librosa.amplitude_to_db(spectogram)\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# librosa.display.specshow(log_spectogram, sr=sr, hop_length=HOP_LENGTH)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stft.shape\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.plot(stft)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFCC\n",
    "# MFCCs = librosa.feature.mfcc(data, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mfcc=13)\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# librosa.display.specshow(MFCCs, sr=sr, hop_length=HOP_LENGTH)\n",
    "# plt.xlabel(\"Time\")\n",
    "# plt.ylabel(\"MFCC\")\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier spectogram\n",
    "# plt.figure(num=None, figsize=(20, 3))\n",
    "# plt.subplot(111)\n",
    "# plt.title('More common (Fourier) spectogram')\n",
    "# plt.specgram(data, Fs=sr)\n",
    "# plt.colorbar()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
