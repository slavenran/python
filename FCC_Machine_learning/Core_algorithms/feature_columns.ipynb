{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making of feature columns (unifying categorical and numeric data frame columns into all numeric columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='n_siblings_spouses', vocabulary_list=(1, 0, 3, 4, 2, 5, 8), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='parch', vocabulary_list=(0, 1, 2, 5, 3, 4), dtype=tf.int64, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='class', vocabulary_list=('Third', 'First', 'Second'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='deck', vocabulary_list=('unknown', 'C', 'G', 'A', 'B', 'D', 'F', 'E'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Southampton', 'Cherbourg', 'Queenstown', 'unknown'), dtype=tf.string, default_value=-1, num_oov_buckets=0), VocabularyListCategoricalColumn(key='alone', vocabulary_list=('n', 'y'), dtype=tf.string, default_value=-1, num_oov_buckets=0), NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='fare', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
    "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
    "y_train = dftrain.pop('survived')\n",
    "y_eval = dfeval.pop('survived')\n",
    "\n",
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']   # caps lock values are constants\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = dftrain[feature_name].unique()    # returns back a list of all values from etc. sex column coded uniquely\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))    # puts all the new values into a new list feature_columns\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))    # puts numeric values into the list\n",
    "\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['male', 'female'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "dftrain['sex'].unique()    # prints out all unique values inside a data frame column\n",
    "# dftrain['embark_town'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input function - makes and trains a model with data we have created above. It uses feature columns at the end to bind all the data to values we have transformed from categorical to numeric + pure numeric. Our evaluation data is used to check the accuracy of our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.7651515\n"
     ]
    }
   ],
   "source": [
    "# this piece of function code is usually always the same\n",
    "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):   # makes an input function\n",
    "    def input_function():   # inner function that will be returned\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))    # created tf dataset with data (input) and its label (output)\n",
    "        if shuffle:\n",
    "            ds = ds.shuffle(1000)   # randomize order of data\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)    # split data into batches of 32 and repeat process for 10 epochs\n",
    "        return ds\n",
    "    return input_function\n",
    "\n",
    "train_input_fn = make_input_fn(dftrain, y_train)\n",
    "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n",
    "\n",
    "# Model that uses Logistic Regression (LinearClassifier is using logistic regression)\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)    # creates a model and uses feature columns initilized above\n",
    "\n",
    "linear_est.train(train_input_fn)   # trains the model\n",
    "result = linear_est.evaluate(eval_input_fn)    # get model metrics/stats by testing on test data\n",
    "\n",
    "clear_output()  # clears console output\n",
    "print(result['accuracy'])   # gives back accuracy metric/stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "C:\\Python39\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\DZILAJ~1\\AppData\\Local\\Temp\\tmpubva8omo\\model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "sex                       female\n",
      "age                         15.0\n",
      "n_siblings_spouses             0\n",
      "parch                          0\n",
      "fare                      8.0292\n",
      "class                      Third\n",
      "deck                     unknown\n",
      "embark_town           Queenstown\n",
      "alone                          y\n",
      "Name: 5, dtype: object\n",
      "1\n",
      "0.68845195\n"
     ]
    }
   ],
   "source": [
    "result = list(linear_est.predict(eval_input_fn)) # gives back a prediction of an input\n",
    "a = 5\n",
    "print(dfeval.loc[a])    # prints out a person we want evaluated (or row we are evaluating)\n",
    "print(y_eval.loc[a])    # prints out if that person has survived or not (data is placed at the same indexes so we can check all our data like this to be unified with values above and below this line of code)\n",
    "print(result[a]['probabilities'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}